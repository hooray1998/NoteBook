
## 过拟合问题
![img](https://github.com/hooray1998/Coursera-ML-AndrewNg-Notes/raw/master/images/72f84165fbf1753cd516e65d5e91c0d3.jpg)img
第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。
![所示](https://github.com/hooray1998/Coursera-ML-AndrewNg-Notes/raw/master/images/be39b497588499d671942cc15026e4a2.jpg)
分类问题中也存在这样的问题：
就以多项式理解，的次数越高，拟合的越好，但相应的预测的能力就可能变差。
### 解决办法
**丢弃一些不能帮助我们正确预测的特征**。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如**PCA**）
**正则化**。 保留所有的特征，但是减少参数的大小（**magnitude**）。
## 代价函数
像上面的模型${h_\theta}\left( x \right)={\theta_{0}}+{\theta_{1}}{x_{1}}+{\theta_{2}}{x_{2}^2}+{\theta_{3}}{x_{3}^3}+{\theta_{4}}{x_{4}^4}$
我们知道是由于高次项的影响导致过拟合，所以可以针对性的设置一些惩罚$\underset{\theta }{\mathop{\min }},\frac{1}{2m}[\sum\limits_{i=1}^{m}{{{\left( {{h}_{\theta }}\left( {{x}^{(i)}} \right)-{{y}^{(i)}} \right)}^{2}}+1000\theta _{3}^{2}+10000\theta _{4}^{2}]}$
但如果有很多特征，我们不知道哪些影响的，那就都添加惩罚，让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设
$J\left( \theta \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{{{({h_\theta}({{x}^{(i)}})-{{y}^{(i)}})}^{2}}+\lambda \sum\limits_{j=1}^{n}{\theta_{j}^{2}}]}$
其中**入**又称为**正则化参数**（**Regularization Parameter**）。 注：根据惯例，我们不对thera0进行惩罚。
对比结果如下：
![](https://github.com/hooray1998/Coursera-ML-AndrewNg-Notes/raw/master/images/ea76cc5394cf298f2414f230bcded0bd.jpg)
但如果正则化参数过大，会导致拟合结果如图中红线所示，欠拟合。
所以要选择一个合适的
## 正则化线性回归
